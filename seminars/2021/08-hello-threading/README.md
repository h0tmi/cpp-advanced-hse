# Введение в многопоточность
### Вспоминаем лекцию
Освежим немного базовые примитивы в памяти.
Позапускаем потоки: [01-hello-threads.cpp](01-hello-threads.cpp).
Посмотрим на race в cout: [hello-hello-threads-hello-threads-threads](02-racy-cout.cpp).
Вспомним про `std::this_thread::get_id()`: возвращается объект класса `std::thread::id`, который можно
хешировать и выводить в поток.

### Применяем
Смотрим, как все ускоряется.
Посчитаем сумму квадратных корней первых 1e9 натуральных чисел: [03-sqrts.cpp](03-sqrts.cpp).
```
$ ./03-sqrts $((1000 ** 3)) 6
num_threads: 6, limit: 1000000000
sum: 2.10819e+13, elapsed: {cpu_time: 3.15542s, wall_time: 0.558082s, ratio: 5.65404x}
```

Насколько дорого запускать потоки?
Решим глупым образом предыдущую задачу: запустим по потоку на каждое число. Чисел, конечно, в этот раз возьмем поменьше, например, 1e5.
Рядом посмотрим на аналогичное решение с одним потоком и потокобезопасной очередью (это черный ящик, про нее достаточно объяснить интерфейс, кондвары на следующем семинаре): [04-launch.cpp](04-launch.cpp).
Видно, что решение с очередью быстрее на порядки.
В чем проблема?
Посмотрим на программу изнутри через `perf trace` / `strace -T`.
Видно, что запуск каждого потока занимает десятки-сотни микросекунд.
Вывод: потоки запускаем редко, обычно --- на старте приложения делаем несколько тредпулов.

### std::async
TLDR: не используем.

Решим нашу задачу, запустив вычисления корней через `std::async` [05-async.cpp](05-async.cpp).
Считается подозрительно долго; посмотрим в `strace`.
`std::async` в `libc++` / `libstdc++` запускает по потоку на каждый вызов, как мы делали только что.
В MSVC набор глобальных тредпулов, что в целом тоже неудобно.
По интерфейсу можно было бы предположить, что стандартная библиотека делает что-то умное под капотом, но нет.
### Mutex
Дает гарантию, что данную _логическую_ секцию кода выполняет один поток.
Есть хороший стандартный `std::mutex`. Интерфейс крайне простой:
```
class Mutex {
public:
    void lock();
    void unlock();
};
```

Покажем, зачем и как использовать. Попробуем написать игрушечный банк [06-bank-racy.cpp](06-bank-racy.cpp).
Видно, что в однопоточном режиме все хорошо, но в многопоточном класс `Bank` использовать нельзя (внимательный читатель может заметить, что мы добавили строчку в `Account::Withdraw`, чтоб провоцировать появление рейсов. Без нее ровно так же UB и ругается TSAN, однако результат менее наглядный).

Что делать?
Добавим мьютекс на каждый аккаунт.
Звучит крайне логично: покроем мьютексом все операции с аккаунтом.
Что делать с транзакцией перевода между аккаунтами?
Берем сначала первый мьютекс, потом второй [06-bank-mutex.cpp](06-bank-mutex.cpp).
BOOM: дедлок (deadlock, в системе нет прогресса).

Такая проблема возникает часто, когда есть больше одного мьютекса, особенно если мьютексы равноправные.
Для решения проблемы есть несколько вариантов; можно руками выстроить порядок на мьютексах (в нашем случае это делается просто),
а можно использовать `std::lock` (или `std::scoped_lock`) [06-bank-lock.cpp](06-bank-lock.cpp).

##### Shared mutex
Бывает, что данные часто читаются, а меняются редко.
В этом случае можно использовать `std::shared_mutex`,
который позволяет нескольким читателям войти в критическую секцию одновременно.

##### Recursive mutex
```
std::mutex mtx;
mtx.lock();
mtx.lock(); // UB
```
Такое разрешает `std::recursive_mutex`, но, субъективно, если он понадобился --- у вас ошибка дизайна.

### thread_local
Хитрый спецификатор хранения (storage duration) переменных.
Довольно много оговорок и тонкостей, используется редко, но знать надо.
Рантайм плюсов автоматически создаст уникальную копию переменной для каждого потока.
[07-thread-local.cpp](07-thread-local.cpp)

### False sharing
Пусть есть набор потоков, каждый из которых регулярно обновляет некоторый счетчик.
Позапускаем: [08-false-sharing.cpp](08-false-sharing.cpp)
Видно, что если добавить выравнивание на 64, то все ускоряется в десятки раз. В чем проблема?
Можно посмотреть в perf report & perf record, ассемблер уже щупали.
False sharing: пишем и читаем кеш-линиями, запись в кеш-линию инвалидирует ее на остальных ядрах.
Связанный эффект: матрицу намного эффективнее обходить по строкам, а не по столбцам.

Как избавиться от хардкода 64?
Никак:(
Есть [std::hardware_destructive_interference_size](https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size),
но он никогда не будет реализован в стдлибах из-за требований на сохранение ABI (Application Binary Interface): после фиксации числа один раз мы не сможем его сломать.
Но сейчас на популярных архитектурах кэш-линии по 64 байта.

Важно, что в примере со счетчиками не обязателен volatile; он используется только чтоб гарантировать запись.
Аналогичное поведение можно наблюдать и с обычными переменными, просто сложнее воспроизводить.

Какой вывод?
Потоки должны как можно меньше писать в общую память.
Если же они пишут, то это должны быть разные регионы, в идеале без пересечений по кэш-линиям.


##### Volatile
`volatile` нельзя использовать в многопоточном окружении.
Используйте `std::atomic<T>`.
`volatile` нужен только для работы с железом,
которое каким-то образом имеет общее с вашим процессом адресное пространство (какой-нибудь датчик в embedding / железо в драйверах OS / VRAM в реальном режиме при загрузке компьютера / etc; в общем --- не наш случай).

http://cxx.isvolatileusefulwiththreads.com


### Atomic
Найдем сумму чисел от 0 до `kLimit` ([09-atomic-sum.cpp](09-atomic-sum.cpp))).
Не сходится; почему?
У нас race condition в RacySum; формально UB, на практике конкретно эта программа просыпает часть чисел.
Что делать? Нам нужно уметь атомарно прибавить число.
Именно это и делает `std::atomic<T>`: он обеспечивает
атомарность и корректность многопоточных операций над вложенным объектом.
Для чисел есть специализации с более широким интерфейсом (`fetch_or`).
Также перегружены некоторые операторы, но чаще пользуются функциями-членами
типа `fetch_add`, это более наглядно.

Пишем на атомиках, получается более долго, но зато ответ правильный и код корректный.

_NB: вы увидите перегрузки методов, которые принимают страшные аргументы типа `std::memory_order`.
Это параметры для тонкой настройки точных эффектов данной атомарной операции; по умолчанию стоит
самый строгий `std::memory_order::seq_cst`, поведение в рамках которого наиболее интуитивно.
Модель памяти будет разбираться на третьем курсе РС на курсе Concurrency.
До тех пор вам достаточно `seq_cst`._

##### shared_ptr
Как мы уже упоминали, `std::shared_ptr` имеет очень важное отличие от того `SharedPtr`, что вы писали.
В стандартной версии счетчики атомарные; это позволяет удобно использовать `std::shared_ptr` в многопоточном окружении: операции копирования и уничтожения указателя потокобезопасны [10-shared-ptr.cpp](10-shared-ptr.cpp).

##### Spinlock
В завершение напишем максимально простой спинлок.
Он работает, но в production такое использовать не надо.
[11-spinlock.cpp](11-spinlock.cpp)

_NB: Торвальдс вообще считает, что использовать спинлоки в пространстве пользователя не надо, и это
довольно сильная позиция. Современные мьютексы делают несколько итераций перед тем, как отправить поток спать. В целом busy-loop считается вредным._
